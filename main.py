#!/usr/bin/env python3
"""
æ–‡æœ¬åˆ†ææ™ºèƒ½ä½“ - å…¼å®¹æ€§å…¥å£æ–‡ä»¶

è¿™ä¸ªæ–‡ä»¶ä¿ç•™äº†åŸå§‹çš„ç®€å•ä½¿ç”¨æ–¹å¼ï¼ŒåŒæ—¶å¯ä»¥å¯åŠ¨æ–°çš„FastAPIæœåŠ¡ã€‚
"""

import os
import sys
from typing import TypedDict, List

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from langgraph.graph import StateGraph, END
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage
from dotenv import load_dotenv
load_dotenv()

# å…¼å®¹åŸç‰ˆæœ¬çš„Stateå®šä¹‰
class State(TypedDict):
    text: str
    classification: str
    entities: List[str]
    summary: str


def create_simple_agent():
    """åˆ›å»ºç®€å•çš„æ–‡æœ¬åˆ†ææ™ºèƒ½ä½“ï¼ˆåŸç‰ˆæœ¬å…¼å®¹ï¼‰"""
    
    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        
    base_url = os.getenv("OPENAI_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")
    model = os.getenv("OPENAI_MODEL", "qwen-plus")
    
    llm = ChatOpenAI(
        model=model,
        temperature=0,
        api_key=api_key,
        base_url=base_url
    )

    def classification_node(state: State):
        """æ–‡æœ¬åˆ†ç±»èŠ‚ç‚¹"""
        prompt = PromptTemplate(
            input_variables=["text"],
            template="å°†ä»¥ä¸‹æ–‡æœ¬åˆ†ç±»åˆ°ä»¥ä¸‹ç±»åˆ«ä¹‹ä¸€ï¼šæ–°é—»ã€åšå®¢ã€ç ”ç©¶ã€å…¶ä»–ã€‚\n\næ–‡æœ¬ï¼š{text}\n\nç±»åˆ«ï¼šï¼ˆåªè¾“å‡ºç±»åˆ«æœ¬èº«ï¼Œä¸è¦ç†ç”±ï¼‰"
        )
        message = HumanMessage(content=prompt.format(text=state["text"]))
        classification = llm.invoke([message]).content.strip()
        return {"classification": classification}

    def entity_extraction_node(state: State):
        """å®ä½“æå–èŠ‚ç‚¹"""
        prompt = PromptTemplate(
            input_variables=["text"],
            template="ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–æ‰€æœ‰å®ä½“ï¼ˆäººç‰©ã€ç»„ç»‡ã€åœ°ç‚¹ï¼‰ã€‚ä»¥é€—å·åˆ†éš”åˆ—è¡¨å½¢å¼è¿”å›ç»“æœã€‚\n\næ–‡æœ¬ï¼š{text}\n\nå®ä½“ï¼š"
        )
        message = HumanMessage(content=prompt.format(text=state["text"]))
        entities = llm.invoke([message]).content.strip().split(", ")
        return {"entities": entities}

    def summarize_node(state: State):
        """æ–‡æœ¬æ‘˜è¦èŠ‚ç‚¹"""
        summarization_prompt = PromptTemplate.from_template(
            """ç”¨ä¸€å¥è¯æ€»ç»“ä»¥ä¸‹æ–‡æœ¬ã€‚\n\næ–‡æœ¬ï¼š{text}\n\næ‘˜è¦ï¼š"""
        )
        chain = summarization_prompt | llm
        response = chain.invoke({"text": state["text"]})
        return {"summary": response.content}

    # åˆ›å»ºå·¥ä½œæµ
    workflow = StateGraph(State)
    workflow.add_node("classification_node", classification_node)
    workflow.add_node("entity_extraction", entity_extraction_node)
    workflow.add_node("summarization", summarize_node)
    
    workflow.set_entry_point("classification_node")
    workflow.add_edge("classification_node", "entity_extraction")
    workflow.add_edge("entity_extraction", "summarization")
    workflow.add_edge("summarization", END)
    
    return workflow.compile()


def run_simple_example():
    """è¿è¡Œç®€å•ç¤ºä¾‹ï¼ˆåŸç‰ˆæœ¬å…¼å®¹ï¼‰"""
    print("ğŸ¤– æ–‡æœ¬åˆ†ææ™ºèƒ½ä½“ - ç®€å•æ¨¡å¼")
    print("=" * 40)
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    app = create_simple_agent()
    
    # æµ‹è¯•æ–‡æœ¬
    sample_text = """
    æˆ‘ä»¬æœ€è¿‘æ›´æ–°äº† 2.5 Pro ç‰ˆæœ¬ï¼Œä»¥å¸®åŠ©å¼€å‘è€…æ„å»ºæ›´ä¸°å¯Œã€æ›´äº’åŠ¨çš„ Web åº”ç”¨ã€‚å¾ˆé«˜å…´çœ‹åˆ°ç”¨æˆ·å’Œå¼€å‘è€…çš„ç§¯æåé¦ˆï¼Œæˆ‘ä»¬å°†ç»§ç»­æ ¹æ®ç”¨æˆ·åé¦ˆè¿›è¡Œæ”¹è¿›ã€‚

é™¤äº†åœ¨å­¦æœ¯åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²å¤–ï¼Œå…¨æ–° 2.5 Pro ç›®å‰åœ¨çƒ­é—¨ç¼–ç¨‹æ’è¡Œæ¦œWebDev Arenaä¸­ä»¥ 1415 çš„ ELO å¾—åˆ†é¢†è·‘ã€‚æ­¤å¤–ï¼Œå®ƒåœ¨LMArenaçš„æ‰€æœ‰æ’è¡Œæ¦œä¸­ä¹Ÿéƒ½ååˆ—å‰èŒ…ï¼Œè¯¥æ’è¡Œæ¦œè¯„ä¼°äººç±»åœ¨å„ä¸ªç»´åº¦ä¸Šçš„åå¥½ã€‚æ­¤å¤–ï¼Œå‡­å€Ÿå…¶ 100 ä¸‡ä¸ª token ä¸Šä¸‹æ–‡çª—å£ï¼Œ2.5 Pro æ‹¥æœ‰ä¸€æµçš„é•¿ä¸Šä¸‹æ–‡å’Œè§†é¢‘ç†è§£æ€§èƒ½ã€‚

è‡ªä»æ•´åˆäº†æˆ‘ä»¬ä¸æ•™è‚²ä¸“å®¶å…±åŒæ„å»ºçš„æ¨¡å‹ç³»åˆ— LearnLM ä»¥æ¥ï¼Œ2.5 Pro ç°å·²æˆä¸ºé¢†å…ˆçš„å­¦ä¹ æ¨¡å‹ã€‚åœ¨è¯„ä¼°å…¶æ•™å­¦æ³•å’Œæœ‰æ•ˆæ€§çš„æ­£é¢æ¯”è¾ƒä¸­ï¼Œæ•™è‚²å·¥ä½œè€…å’Œä¸“å®¶åœ¨å„ç§åœºæ™¯ä¸­éƒ½æ›´é’ç Gemini 2.5 Proã€‚æ­¤å¤–ï¼Œå®ƒåœ¨æ„å»ºå­¦ä¹ å‹ AI ç³»ç»Ÿçš„äº”é¡¹å­¦ä¹ ç§‘å­¦åŸåˆ™ä¸­ï¼Œæ¯ä¸€é¡¹éƒ½è¶…è¶Šäº†é¡¶çº§æ¨¡å‹ã€‚

è¯·å‚é˜…æˆ‘ä»¬æ›´æ–°çš„Gemini 2.5 Pro æ¨¡å‹å¡å’ŒGemini æŠ€æœ¯é¡µé¢ä»¥äº†è§£æ›´å¤šä¿¡æ¯ã€‚
    """
    
    print(f"ğŸ“ åˆ†ææ–‡æœ¬: {sample_text.strip()}")
    print("\nğŸ”„ æ­£åœ¨åˆ†æ...")
    
    # æ‰§è¡Œåˆ†æ
    state_input = {"text": sample_text.strip()}
    result = app.invoke(state_input)
    
    # è¾“å‡ºç»“æœ
    print("\nğŸ“Š åˆ†æç»“æœ:")
    print(f"åˆ†ç±»ç»“æœ: {result['classification']}")
    print(f"å®ä½“åˆ—è¡¨: {result['entities']}")
    print(f"æ‘˜è¦å†…å®¹: {result['summary']}")


def start_api_server():
    """å¯åŠ¨FastAPIæœåŠ¡å™¨"""
    print("ğŸš€ å¯åŠ¨æ–‡æœ¬åˆ†æAPIæœåŠ¡å™¨...")
    
    try:
        from src.main import app
        import uvicorn
        
        # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
        host = os.getenv("APP_HOST", "0.0.0.0")
        port = int(os.getenv("APP_PORT", "8000"))
        debug = os.getenv("APP_DEBUG", "false").lower() == "true"
        
        uvicorn.run(
            "src.main:app",
            host=host,
            port=port,
            reload=debug
        )
    except ImportError as e:
        print(f"âŒ æ— æ³•å¯åŠ¨APIæœåŠ¡å™¨: {e}")
        print("è¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–: pip install -r requirements.txt")
        sys.exit(1)


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) > 1:
        if sys.argv[1] == "server":
            start_api_server()
        elif sys.argv[1] == "simple":
            run_simple_example()
        elif sys.argv[1] == "help":
            print("ä½¿ç”¨æ–¹æ³•:")
            print("  python main.py simple   - è¿è¡Œç®€å•ç¤ºä¾‹")
            print("  python main.py server   - å¯åŠ¨APIæœåŠ¡å™¨")
            print("  python main.py help     - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
        else:
            print(f"æœªçŸ¥å‘½ä»¤: {sys.argv[1]}")
            print("ä½¿ç”¨ 'python main.py help' æŸ¥çœ‹å¸®åŠ©")
    else:
        # é»˜è®¤è¡Œä¸ºï¼šå…ˆå°è¯•ç®€å•ç¤ºä¾‹ï¼Œç„¶åæç¤ºç”¨æˆ·
        print("ğŸ¤– æ–‡æœ¬åˆ†ææ™ºèƒ½ä½“")
        print("=" * 30)
        print("é€‰æ‹©è¿è¡Œæ¨¡å¼:")
        print("1. ç®€å•ç¤ºä¾‹ (python main.py simple)")
        print("2. APIæœåŠ¡å™¨ (python main.py server)")
        print()
        
        choice = input("è¯·é€‰æ‹© [1/2]: ").strip()
        
        if choice == "1":
            run_simple_example()
        elif choice == "2":
            start_api_server()
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡Œç®€å•ç¤ºä¾‹...")
            run_simple_example()


if __name__ == "__main__":
    main()
